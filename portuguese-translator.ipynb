{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:33:20.543310Z",
     "start_time": "2020-04-06T21:33:20.538284Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:33:24.852889Z",
     "start_time": "2020-04-06T21:33:20.546068Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:33:24.993397Z",
     "start_time": "2020-04-06T21:33:24.860388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from : https://www.manythings.org/anki/  \n",
    "References:  Deep Learning: Advanced NLP and RNNs (Lazy Programmer), Keras and Tensorflow documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:29:51.039355Z",
     "start_time": "2020-04-06T21:29:51.035355Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_SAMPLES = 10000\n",
    "MAX_SEQ_LEN = 100\n",
    "#MAX_NUM_WORDS = 20000 # It's correlated with the number of samples\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Cleaning the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:29:57.361812Z",
     "start_time": "2020-04-06T21:29:57.259353Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = './por.txt'\n",
    "with open(filepath, encoding='UTF-8') as f:\n",
    "    eng2por = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:29:58.774865Z",
     "start_time": "2020-04-06T21:29:58.722956Z"
    }
   },
   "outputs": [],
   "source": [
    "eng2por = eng2por.split('\\n')[:-1] # Breaking in lines first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit the number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:32:01.223147Z",
     "start_time": "2020-04-06T21:32:01.024560Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(234)\n",
    "eng2por = np.random.choice(eng2por, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting English and Portuguese texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:32:03.423174Z",
     "start_time": "2020-04-06T21:32:03.376156Z"
    }
   },
   "outputs": [],
   "source": [
    "input_texts = [line.split('\\t')[0] for line in eng2por]\n",
    "translations = [line.split('\\t')[1] for line in eng2por]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs (English)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:33:28.928251Z",
     "start_time": "2020-04-06T21:33:28.704148Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_inputs = Tokenizer()\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting input word to index map and maximum size (for padding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:34:49.078801Z",
     "start_time": "2020-04-06T21:34:49.071841Z"
    }
   },
   "outputs": [],
   "source": [
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding inputs (paddings are 'pre' by default) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:34:50.862579Z",
     "start_time": "2020-04-06T21:34:50.822515Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:17:50.229229Z",
     "start_time": "2020-04-04T17:17:50.223227Z"
    }
   },
   "source": [
    "Saving the input dictionary to calculate the embedding matrix (secondary script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:34:52.278158Z",
     "start_time": "2020-04-06T21:34:52.274496Z"
    }
   },
   "outputs": [],
   "source": [
    "idx2word = {idx:word for (word, idx) in word2idx_inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:35:33.708026Z",
     "start_time": "2020-04-06T21:35:33.701800Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./idx2word_encoder', 'wb') as f:\n",
    "    pickle.dump(idx2word, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translations (Portuguese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding tags to translations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:35:37.773727Z",
     "start_time": "2020-04-06T21:35:37.766538Z"
    }
   },
   "outputs": [],
   "source": [
    "translations = ['<sos> '+line+' <eos>' for line in translations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:35:50.568997Z",
     "start_time": "2020-04-06T21:35:50.406887Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_translations = Tokenizer(filters='')\n",
    "tokenizer_translations.fit_on_texts(translations)\n",
    "translations_sequences = tokenizer_translations.texts_to_sequences(translations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting translations dictionary, number of words and maximum target lentgh (for padding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:35:51.757886Z",
     "start_time": "2020-04-06T21:35:51.754881Z"
    }
   },
   "outputs": [],
   "source": [
    "word2idx_translations = tokenizer_translations.word_index\n",
    "num_words_output = len(word2idx_translations) + 1 # To account for 0 (padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating output and input for translations (Forced Teaching):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:36:01.425083Z",
     "start_time": "2020-04-06T21:36:01.415044Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_inputs = [sequence[:-1] for sequence in translations_sequences]\n",
    "trans_outputs = [sequence[1:] for sequence in translations_sequences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets are the trans_outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:36:17.335726Z",
     "start_time": "2020-04-06T21:36:17.331724Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len_target = max(len(s) for s in trans_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding data for the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:36:21.360233Z",
     "start_time": "2020-04-06T21:36:21.282484Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_inputs = pad_sequences(trans_inputs, padding='post',\n",
    "                               maxlen=max_len_target)\n",
    "targets = pad_sequences(trans_outputs, padding='post',\n",
    "                            maxlen=max_len_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do this because we can't one hot encode the whole target decoder sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:10.236023Z",
     "start_time": "2020-04-06T21:39:10.228020Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, encoder_inputs, decoder_inputs, targets,\n",
    "                 batch_size, num_words_output, shuffle=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_words_output = num_words_output\n",
    "        \n",
    "        # Data\n",
    "        self.encoder_inputs = encoder_inputs\n",
    "        self.decoder_inputs = decoder_inputs\n",
    "        self.targets = targets\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end() # Shuffle the dataset betweem epochs\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return int(self.encoder_inputs.shape[0] / self.batch_size)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        rows = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        enc_inp = self.encoder_inputs[rows, :]\n",
    "        dec_inp = self.decoder_inputs[rows, :]\n",
    "        dec_out_one_hot = to_categorical(self.targets[rows, :], \n",
    "                                         num_classes=self.num_words_output)\n",
    "        \n",
    "        return [enc_inp, dec_inp], dec_out_one_hot\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.encoder_inputs.shape[0])\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Model with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:15.559381Z",
     "start_time": "2020-04-06T21:39:15.556348Z"
    }
   },
   "outputs": [],
   "source": [
    "LATENT_DIM = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading embedding matrix and preparing embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:15.573054Z",
     "start_time": "2020-04-06T21:39:15.563414Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.load('./embedding_matrix_encoding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:15.580992Z",
     "start_time": "2020-04-06T21:39:15.575022Z"
    }
   },
   "outputs": [],
   "source": [
    "num_words = len(word2idx_inputs) + 1 # To account for padding\n",
    " \n",
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    EMBEDDING_DIM,\n",
    "    weights = [embedding_matrix],\n",
    "    input_length = max_len_input\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:21.792947Z",
     "start_time": "2020-04-06T21:39:21.411041Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_len_input, ))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(LATENT_DIM, return_state=True, dropout=0.5)\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "# We only need the final encoder states\n",
    "encoder_states = [h, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:22.181886Z",
     "start_time": "2020-04-06T21:39:21.794841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input and embedding for decoder (not pre-trained in this case)\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_state=True, return_sequences=True,\n",
    "                    dropout=0.5)\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "    decoder_inputs_x,\n",
    "    initial_state = encoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:22.216987Z",
     "start_time": "2020-04-06T21:39:22.183887Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:22.222889Z",
     "start_time": "2020-04-06T21:39:22.218911Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder],\n",
    "              decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:39:22.257914Z",
     "start_time": "2020-04-06T21:39:22.224886Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T21:41:10.043886Z",
     "start_time": "2020-04-06T21:41:10.038888Z"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(encoder_inputs, decoder_inputs, targets,\n",
    "                               BATCH_SIZE, num_words_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:12:39.958497Z",
     "start_time": "2020-04-06T21:45:20.010408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 1.3705 - accuracy: 0.8055\n",
      "Epoch 2/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 1.2828 - accuracy: 0.8090\n",
      "Epoch 3/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 1.2221 - accuracy: 0.8153\n",
      "Epoch 4/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 1.1652 - accuracy: 0.8215\n",
      "Epoch 5/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 1.1104 - accuracy: 0.8266\n",
      "Epoch 6/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 1.0609 - accuracy: 0.8310\n",
      "Epoch 7/30\n",
      "156/156 [==============================] - 180s 1s/step - loss: 1.0132 - accuracy: 0.8354\n",
      "Epoch 8/30\n",
      "156/156 [==============================] - 177s 1s/step - loss: 0.9687 - accuracy: 0.8397\n",
      "Epoch 9/30\n",
      "156/156 [==============================] - 176s 1s/step - loss: 0.9255 - accuracy: 0.8429\n",
      "Epoch 10/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 0.8850 - accuracy: 0.8462\n",
      "Epoch 11/30\n",
      "156/156 [==============================] - 174s 1s/step - loss: 0.8457 - accuracy: 0.8490\n",
      "Epoch 12/30\n",
      "156/156 [==============================] - 174s 1s/step - loss: 0.8086 - accuracy: 0.8520\n",
      "Epoch 13/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 0.7730 - accuracy: 0.8554\n",
      "Epoch 14/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 0.7400 - accuracy: 0.8584\n",
      "Epoch 15/30\n",
      "156/156 [==============================] - 174s 1s/step - loss: 0.7080 - accuracy: 0.8617\n",
      "Epoch 16/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 0.6779 - accuracy: 0.8652\n",
      "Epoch 17/30\n",
      "156/156 [==============================] - 177s 1s/step - loss: 0.6495 - accuracy: 0.8682\n",
      "Epoch 18/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 0.6225 - accuracy: 0.8714\n",
      "Epoch 19/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 0.5970 - accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 0.5735 - accuracy: 0.8783\n",
      "Epoch 21/30\n",
      "156/156 [==============================] - 174s 1s/step - loss: 0.5494 - accuracy: 0.8817\n",
      "Epoch 22/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 0.5286 - accuracy: 0.8856\n",
      "Epoch 23/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 0.5076 - accuracy: 0.8898\n",
      "Epoch 24/30\n",
      "156/156 [==============================] - 176s 1s/step - loss: 0.4880 - accuracy: 0.8932\n",
      "Epoch 25/30\n",
      "156/156 [==============================] - 173s 1s/step - loss: 0.4692 - accuracy: 0.8967\n",
      "Epoch 26/30\n",
      "156/156 [==============================] - 175s 1s/step - loss: 0.4527 - accuracy: 0.8991\n",
      "Epoch 27/30\n",
      "156/156 [==============================] - 176s 1s/step - loss: 0.4363 - accuracy: 0.9028\n",
      "Epoch 28/30\n",
      "156/156 [==============================] - 174s 1s/step - loss: 0.4206 - accuracy: 0.9055\n",
      "Epoch 29/30\n",
      "156/156 [==============================] - 174s 1s/step - loss: 0.4063 - accuracy: 0.9086\n",
      "Epoch 30/30\n",
      "156/156 [==============================] - 174s 1s/step - loss: 0.3917 - accuracy: 0.9115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cfac10f908>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=data_generator, epochs = 30, workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the encoder model from before to calculate the initial states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:22:13.254101Z",
     "start_time": "2020-04-06T23:22:13.247101Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder inputs will be different on inference (only one word instead of Forced Teaching):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:22:13.816195Z",
     "start_time": "2020-04-06T23:22:13.256102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hidden States\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM, ))\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Initial Word\n",
    "decoder_inputs_single = Input(shape=(1,)) # For this case it will be just a number\n",
    "\n",
    "# Passing this word on the embedding\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# Passing the embedded word on the decoder layer\n",
    "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x,\n",
    "                                     initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [h, c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder model receives the word input and the states from the encoder and returns the output and its owe states (for the next word):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:22:13.822102Z",
     "start_time": "2020-04-06T23:22:13.818099Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the function to generate translations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:22:13.835097Z",
     "start_time": "2020-04-06T23:22:13.824101Z"
    }
   },
   "outputs": [],
   "source": [
    "idx2word_translations = {idx:word for (word, idx) in word2idx_translations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:22:13.845097Z",
     "start_time": "2020-04-06T23:22:13.837100Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(input_seq):\n",
    "    \n",
    "    # Run the original sentence on the encoder\n",
    "    states_values = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Start of sentence token\n",
    "    decoder_input = np.zeros((1,1))\n",
    "    decoder_input[0,0] = word2idx_translations['<sos>']\n",
    "    \n",
    "    # Token to end translation\n",
    "    eos_token = word2idx_translations['<eos>']\n",
    "    \n",
    "    # Let's generate the translation\n",
    "    translated_sentence = []\n",
    "    for _ in range(max_len_target):\n",
    "        \n",
    "        # Pass the input through the decoder\n",
    "        output_probs, h, c = decoder_model.predict(\n",
    "           [decoder_input] + states_values\n",
    "        )\n",
    "        \n",
    "        # Predicted next word id\n",
    "        predicted_id = np.argmax(output_probs[0, 0, :])\n",
    "        \n",
    "        # If the predicted word is the eos token, break the loop\n",
    "        if predicted_id == eos_token:\n",
    "            break\n",
    "        \n",
    "        # If not, we add the word to the translated sentence\n",
    "        word = ''\n",
    "        if predicted_id > 0:\n",
    "            word = idx2word_translations[predicted_id]\n",
    "            translated_sentence.append(word)\n",
    "            \n",
    "        # Update the decoder_input and states\n",
    "        decoder_input[0,0] = predicted_id\n",
    "        states_values = [h, c]\n",
    "    \n",
    "    return ' ' .join(translated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking some translations on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:25:05.167834Z",
     "start_time": "2020-04-06T23:25:05.139858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom still hasn't taken down his Christmas tree.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tom ainda não desmontou a sua árvore de natal dele.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.choice(len(input_texts))\n",
    "\n",
    "print(input_texts[i])\n",
    "translate(encoder_inputs[i:i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating new sentences (this is much harder, since our vocabulary is very limited in the baseline case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:28:19.463502Z",
     "start_time": "2020-04-06T23:28:19.460533Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(phrase):\n",
    "    \n",
    "    tokens = tokenizer_inputs.texts_to_sequences(phrase)\n",
    "    padded = pad_sequences(tokens, maxlen=max_len_input)\n",
    "    \n",
    "    return padded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T23:30:41.566944Z",
     "start_time": "2020-04-06T23:30:41.539914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu tenho que fazer isso com o tom.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = ['I have to be honest here, Tom']\n",
    "translate(preprocess(phrase))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
